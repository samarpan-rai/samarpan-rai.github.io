---
layout: page
title:  "Is dit woord de of het?  "
subtitle: "Waneer is het woord 'de' en waneer is het woord 'het'?"
date:   2019-06-20 19:19 +0100
categories: ["data-science"]
---
After living in the Netherlands for the past five years, I have finally started to learn Dutch seriously and seems like I am not alone. A survey done by [DutchNews.nl](https://www.dutchnews.nl/news/2020/05/coronvirus-in-the-netherlands-what-you-said-in-our-survey/) claims that 17% of the respondents were learning Dutch during.

I am currently in A1-A2 level and I am just starting to learn about articles De/Het in Dutch.In dutch language the word 'de' or 'het' is always before the Noun. If there is 'de' before the noun then the word is probably male or female. If it has 'het' then it means that the word is gender neutral. This is particularly confusing for me because none of the languages I know have explicit gender before a Noun.

## Problem

So in order to properly write/speak dutch, I need to know if a word is de or het (article). When my dutch teacher said, "We Dutch are crazy so there are no clear rules!" (paraphrased). This means I have to memorize every word with its article. .

The only problem is that I hate memorizing! I always liked math and science because there was a clear reasoning behind it. Language is not always like that. There are few rules but there are always exceptions to the rule. This adds the difficultly in learning the language.


## Solution

Every Dutch person I know kind-of intuitively knows the rule because they have been speaking the language since they were born. What if we could map out this intuition? What if we could extract rules from the chaos using data?

This is exactly I will try to do in this blog post. The goal of this post are as follows:

* Extract the nouns and its corresponding article from openly available online texts
* Find the relation between the words and graph them
* Find patterns to help understand the global pattern behind de/het in Dutch
* Hopefully learn to use Dutch better

If you are just interested in the fancy figures then you can go to the [result](#result) section directly

**Side note** : I know that there already exists some rule. I will list them below. Do correct me if I am wrong.
1. If the word ends with 'jes' then the article is always 'het'.



### Technical jargon


  1. I will be using various NLP based technology to accomplish them. Namely, I will make use of [spaCy](https://spacy.io/) to extract the Nouns and the vector representation. For larger models, spaCy provides these [vector](https://spacy.io/usage/vectors-similarity#_title) representations out-of-the-box.

  2. I will use [t-SNE](https://scikit-learn.org/stable/modules/generated/sklearn.manifold.TSNE.html) to reduce the n-dimensional vector representation to 2D. I am particularly using t-SNE because I don't know the exact number of clusters. t-SNE magically (not [really](https://mlexplained.com/2018/09/14/paper-dissected-visualizing-data-using-t-sne-explained/)) does this for you.

Without further ado, lets get started!

## Data collection

I am using data made openly available from [Spoken wikipedia Corpus](https://nats.gitlab.io/swc/). They have over 224h of spoken dutch language content. I am only interested in the text so I downloaded the dutch text from [here](https://www2.informatik.uni-hamburg.de/nats/pub/SWC/SWC_Dutch_no_audio.tar.xz).

So I am lucky that I do not have to manually collect articles from the Internet. The data is compressed file that can be extracted easily.


A quick snap shot shows that the each there are document about various topics like [Zwarte Piet](https://en.wikipedia.org/wiki/Zwarte_Piet) and [Zwolle](https://en.wikipedia.org/wiki/Zwolle)

![Folder-structure](/assets/img/deofhet_file_struct.png)

Upon opening each directory we see that there are differet files. I quickly saw that I only needed `audiometa.txt`.


  ![Needed-file](/assets/img/deofhet_file_selection.png)


I collect all these files and put them together in a pandas dataframe for further analysis. You can find the code for automatically downloading the compresssed file, extracting the text and storing in data frame [here](https://github.com/samarpan-rai/DeOfHet/blob/master/1.%20Download%20and%20collect%20data.ipynb)

There are 3065 possibly readable documents. Out of them, 3051 are machine readable.

## Data pre-processing

During this step, I extracted the nouns from the text using spaCy's powerful [linguistic features](https://spacy.io/usage/linguistic-features). The linguistic feature includes things like Part-of-speech (Noun, Verb, Adjective). I think it is super cool that it handles the parsing and extraction and makes the whole process as painless as possible. For example, the following displaCy output makes it super easy to see relation between text.
<div class="container overflow-auto">
  {% include posts_html_data/displaCy.html %}
</div>
It provides these neat dependencies between words that enables me to quickly check for pattern and extract the data I need. For example, we know that 'deur' (door) is a noun. It's article is 'de' but how can we extract it based on this relation? We can extract the children that point away from the word 'deur' i.e De, zwarte.


I use very simple check to extract the article from all the documents. I have tried to write it as a psuedocode below.

```
if word is Noun:
  extract its children
  check if the children have article
  if one of the child has article:
    save the article and word

```

On top, I also selected spaCy's vector representation of the word. I can now use this valueable high-dimensional data for various purposes. For instance, it can be used to find relation between other words using [cosine similarity](https://en.wikipedia.org/wiki/Cosine_similarity). I will provide this to t-SNE algorithm to find the the projection in 2D space. Furthermore, this vector data can also be used to train machine learning aglorithm that can classify if a word requires De or Het.

## Cluster building

t-Distributed Stochastic Neighbor Embedding (t-SNE) is quite a mouthful. I will not go too much details into how the algorithm works but in short, t-SNE captures creating *non-linear* structure while respecting crowding problem.

An excerpt from [this](https://mlexplained.com/2018/09/14/paper-dissected-visualizing-data-using-t-sne-explained/) helpful explanation.


  > Step 1: In the high-dimensional space, create a probability distribution that dictates the relationships between various neighboring points

  > Step 2: It then tries to recreate a low dimensional space that follows that probability distribution as best as possible.

## Result

After some magic, we can see this chart! Feel free to hover around it.

<div class="container overflow-auto">
  {% include posts_html_data/2d_tsne_woorden_distributie.html %}
</div>



##
